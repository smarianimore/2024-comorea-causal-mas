<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>Pervasive Causal Discovery @ CoMoReA 2024</title>
    <meta content="Talk 'Distributed Discovery of Causal Networks in Pervasive Environments' given by Stefano Mariani at CoMoReA 2024" name="description">
    <meta content="Stefano Mariani" name="author">

    <meta content="yes" name="apple-mobile-web-app-capable">
    <meta content="black-translucent" name="apple-mobile-web-app-status-bar-style">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">

    <link rel="stylesheet" href="reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css" id="theme" />

    <!-- Theme used for syntax highlighted code -->
    <link
      rel="stylesheet"
      href="reveal.js/plugin/highlight/monokai.css"
      id="highlight-theme"
    />

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement('link');
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName('head')[0].appendChild(link);
    </script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">

        <section data-transition="convex" data-background-image="res/percom-home.png" data-background-opacity=0.25 data-background-size="cover">
          <section>
            <p>
              <small><em>Workshop on Context and Activity Modelling and Recognition</em> <br> Biarritz, France, 11/3/2024 </small>
            </p>
            <hr>
            <br>
            <h3> Distributed Discovery of Causal Networks in Pervasive Environments </h3>
            <hr>
            <p> <a href="https://smarianimore.github.io">Stefano Mariani</a>, Franco Zambonelli </p>
            <p>
              <small><em> University of Modena and Reggio Emilia </em></small>
            </p>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <style>
                .container{
                  display: flex;
                }
                .col{
                  flex: 1;
                }
              </style>
              <p>
                <small><strong> Distributed Discovery of Causal Networks in Pervasive Environments </strong></small>
              </p>
              <hr>
              <div class="container">
                <div class="col">
                  <img data-src="res/qrcode_smarianimore.github.io.png">
                </div>
                <div class="col">
                  <br>
                  <br>
                  Scan QR code :)
                  <br>
                  <br>
                  <ul><small>
                    <li> Browse slides yourself at your own pace </li>
                    <li> Navigation buttons at bottom right </li>
                    <li> Scroll all the way down first, then right </li>
                    <li> If on desktop, &lt;Esc&gt; to enter/exit overview </li>
                  </small></ul>
                </div>
              </div>
              <hr>
              <p><small><em> <a href="https://smarianimore.github.io">Stefano Mariani</a>, Franco Zambonelli </em></small></p>
            </script>
          </section>
        </section>

        <section data-transition="convex">
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/motivations.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Motivation
              ----

              * Achieving goals in pervasive environments requires **context awareness** to adapt to environment dynamics
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/motivations.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Motivation
              ----

              * Achieving goals in pervasive environments requires **context awareness** to adapt to environment dynamics
              * **Causal models** (i.e. networks of cause-effect relations)
                - can deliver such awareness
                - express causation, not mere correlation
                - uniformly enable prediction, "what-if" analysis, planning, diagnosis, explainability
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/motivations.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Motivation
              ----

              * We embed causal models in software programs all the time!
                - e.g. `IF cause THEN effects`
                - e.g. `cause.callback(effects)`
                - e.g. `belief :- intention.`
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/motivations.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Motivation
              ----

              * We embed causal models in software programs all the time!
                - e.g. `IF cause THEN effects`
                - e.g. `cause.callback(effects)`
                - e.g. `belief :- intention.`
              * Requires *design-time, expert, domain knowledge*
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/motivations.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Motivation
              ----

              * We embed causal models in software programs all the time!
                - e.g. `IF cause THEN effects`
                - e.g. `cause.callback(effects)`
                - e.g. `belief :- intention.`
              * Requires *design-time, expert, domain knowledge*

              <p style="color: red"> <em>What if that's not available?</em> </p>
            </script>
          </section>

          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/goals.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Goal
              ----

              **Learn** causal networks at **run-time**!
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/goals.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Goal
              ----

              **Learn** causal networks at **run-time**!

              * Called **causal discovery** in related literature
                - assumes *full observability* of environment...
                - ...by an *individual* processing node...
                - ...aimed at learning the *Global Causal Network* (GCN)---whole environment
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/goals.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Goal
              ----

              **Learn** causal networks at **run-time**!

              * Called **causal discovery** in related literature
                - assumes *full observability* of environment...
                - ...by an *individual* processing node...
                - ...aimed at learning the *Global Causal Network* (GCN)---whole environment

              <p style="color: red"> <em>What if that's not feasible?</em> </p>
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              ## Motivation
              ----

              * Pervasive computing infrastructures are **distributed** in nature
                - devices (sensors and actuators) scattered in the environment
                - 3-tier architecture from Edge-to-Cloud
                - Edge and Fog nodes have **partial observability/control**
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              ## Motivation
              ----

              * Pervasive computing infrastructures are **distributed** in nature
                - sensors and actuators scattered in the environment
                - 3-tier processing architecture from Edge-to-Cloud
                - processing nodes have **partial observability/control**
              * *Individual Causal Networks* (ICNs) do not account for *influences* amongst nodes
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/goals.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Goal
              ----

              <p style="color: green"> Learn a <strong>Minimal Causal Network</strong> (MCN) with multiple nodes with partial observability/control! </p>

              <img data-src="res/2024-comorea-causal-mas-scenario.png" width="70%">
            </script>
          </section>

          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/contribution.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Contribution
              ----

              **Collaborative multi-node protocol for distributed causal discovery**

              1. formulate learning and coordination problems
              2. describe collaborative learning protocol
              3. evaluate accuracy of MCN against ICN and GCN
            </script>
          </section>
        </section>

        <section data-transition="convex">
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/causal-discovery.jpg" data-background-opacity="0.15" data-background-size="cover" -->
              ## Preliminaries
              ----

              * Causal models capture cause-effect relationships in *networks* of interacting variables
              * Purely statistical ML approaches capture mere *correlation*, instead
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/causal-discovery.jpg" data-background-opacity="0.15" data-background-size="cover" -->
              ## Preliminaries
              ----

              * Causal models capture cause-effect relationships in *networks* of interacting variables
              * Purely statistical ML approaches capture mere *correlation*, instead

              Cornerstone to causal discovery is the notion of **intervention**
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/causal-discovery.jpg" data-background-opacity="0.15" data-background-size="cover" -->
              ## Preliminaries
              ----

              * Intuition:
                - act on a variable *all others being untouched*
                - observe changes
                - infer cause-effect relation accordingly
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/causal-discovery.jpg" data-background-opacity="0.15" data-background-size="cover" -->
              ## Preliminaries
              ----

              * Intuition:
                - act on a variable *all others being untouched*
                - observe changes
                - infer cause-effect relation accordingly
              * Formalised as do operator $do(X=x)$
                - $\mathcal{P}(Temp) \neq \mathcal{P}(Temp | do(AC=on))$
                - $\mathcal{P}(AC) = \mathcal{P}(AC | do(Temp=t))$
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/causal-discovery.jpg" data-background-opacity="0.15" data-background-size="cover" -->
              ## Preliminaries
              ----

              * Intervention requires **control** (e.g. actuators, not sensors!)
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/causal-discovery.jpg" data-background-opacity="0.15" data-background-size="cover" -->
               Preliminaries
              ----

              * Intervention requires **control** (e.g. actuators, not sensors!)
              * Causal discovery possible even with no control
                - *identifiability conditions* (i.e. assumptions on variables) must hold
                - e.g. no cycles, no unknown confounders, constraints on stationarity, ...
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/causal-discovery.jpg" data-background-opacity="0.15" data-background-size="cover" -->
              ## Preliminaries
              ----

              * Intervention requires **control** (e.g. actuators, not sensors!)
              * Causal discovery possible even with no control
                - *identifiability conditions* (i.e. assumptions on variables) must hold
                - e.g. no cycles, no unknown confounders, constraints on stationarity, ...

              Learnt causal model can be conveniently represented as a DAG (a network)
            </script>
          </section>
        </section>

        <section data-transition="convex">
          <section data-markdown data-auto-animate>
            <script type="text/template">
              ## Problem setting
              ----

              <img data-src="res/2024-comorea-causal-mas-scenario.png">
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-background-image="res/2024-comorea-causal-mas-scenario.png" data-background-opacity="0.1" data-background-size="cover" -->
              ## Problem setting
              ----

              <style>
                .container{
                  display: flex;
                }
                .col{
                  flex: 1;
                }
              </style>
              <div class="container">
                <div class="col">
                  <img data-src="res/2024-comorea-causal-mas-scenario.png">
                </div>
                <div class="col">
                  <ul><small>
                    <li> Multiple Fog nodes having each <strong>partial observability</strong> over sensors and actuators </li>
                    <li class="fragment"> Each wants to learn its <strong>MCN = ICN + causal links with others' sensors and actuators</strong> </li>
                    <li class="fragment"> GCN not needed but obtainable from MCNs </li>
                    <li class="fragment"> Each node has algorithm to learn ICN (in isolation) </li>
                    <li class="fragment"> Network is not partitioned </li>
                    <li class="fragment"> Nodes can trust each other </li>
                  </small></ul>
                </div>
              </div>
            </script>
          </section>
        </section>

        <section data-transition="convex">
          <section data-markdown data-auto-animate>
            <script type="text/template">
              ## Proposed protocol: main
              ----

              <img data-src="res/protocol-main.png" width="55%">
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              ## Proposed protocol: sub
              ----

              <img data-src="res/protocol-sub.png" width="70%">
            </script>
          </section>
          <section data-markdown>
            <script type="text/template">
              <!-- .slide: data-transition="slide" data-background-image="res/coordination-issues.jpg" data-background-opacity="0.15" data-background-size="70%" -->
              <h3 style="color: red"> Coordination issues </h3>

              ----

              * Interventions must be done *one at a time, all other conditions being equal*, by definition
              <ul><small>
                <li class="fragment" data-fragment-index="1"> calls for <strong>distributed mutual exclusion</strong> </li>
                <li class="fragment" data-fragment-index="1"> no ground truth $\implies$ no heuristic </li>
              </small></ul>
              * &shy;<!-- .element: class="fragment" -->Interventions in real world (actuators) may *take time*
              <ul><small>
                <li class="fragment" data-fragment-index="2"> calls for intervention-observation time window </li>
                <li class="fragment" data-fragment-index="2"> <strong>negotiation</strong> of duration and frequency </li>
              </small></ul>

              &shy;<!-- .element: class="fragment" -->Exacerbated as $N \rightarrow \infty$ <br> and comm. topology $\neq$ fully connected

              <p class="fragment" style="color: darkgrey"> <em>(future work)</em> </p>
            </script>
          </section>
        </section>

        <section data-transition="convex">
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ### Evaluation scenario
              ----

              <img data-src="res/icasa.png" width="55%" height="75%">
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ### Evaluation scenario
              ----

              <style>
                .container{
                  display: flex;
                }
                .col{
                  flex: 1;
                }
              </style>
              <div class="container">
                <div class="col">
                  <img data-src="res/fig60_1.png" height="75%">
                </div>
                <div class="col">
                  <img data-src="res/icasa.png" width="55%" height="75%">
                </div>
              </div>
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ### Evaluation scenario
              ----

              <style>
                .container{
                  display: flex;
                }
                .col{
                  flex: 1;
                }
              </style>
              <div class="container">
                <div class="col">
                  <img data-src="res/fig60_1.png" height="75%">
                </div>
                <div class="col">
                  <img data-src="res/icasa.png" width="55%" height="75%">
                </div>
              </div>
              <ul>
                <li> iCasa (simulated) smart home </li>
                <li> 2 agents: "red" (girl, $\mathcal{A}_1$) and "blue" (boy, $\mathcal{A}_2$) </li>
                <li> Actuators (circles) $\in \mathcal{C}$ and sensors (boxes) $\in U$ </li>
              </ul>
            </script>
          </section>
          <section data-markdown>
            <script type="text/template">
              <!-- .slide: data-transition="slide" data-background-image="res/metrics.jpg" data-background-opacity="0.15" data-background-size="contain" -->
              ## Performance metrics
              ----

              * **false positives** (FP): learnt edges not in ground truth (GT)
              * **false negatives** (FN): edges in GT not learnt
              * (extended) **Structural Hamming Distance** (SHD): FP + FN + unknowns (missing edges due to $v \notin P_i$)
              * **time**: to learn $\mathcal{L}$ (baseline) or $M$ (multi-agent)
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ## Agent $\mathcal{A}_1$
              ----

              <div class="r-stack">
                <img data-src="res/fig61_net_v2_shaded_1.png" height="75%">
                <img class="fragment" data-src="res/fig63_net_v2_shaded_1.png" height="75%">
              </div>
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ## Agent $\mathcal{A}_1$
              ----

              <style>
                .container{
                  display: flex;
                }
                .col{
                  flex: 1;
                }
              </style>
              <div class="container">
                <div class="col">
                  <img data-src="res/fig61_net_v2_shaded_1.png">
                </div>
                <div class="col">
                  <img data-src="res/fig63_net_v2_shaded_1.png">
                </div>
              </div>
              <div class="container">
                <div class="col">
                  <ul>
                    <li> FP$_{\mathcal{L}_1}$ = FP$_{M_1}$ </li>
                    <li> FN$_{\mathcal{L}_1}$ = FN$_{M_1}$ </li>
                  </ul>
                </div>
                <div class="col">
                  <ul>
                    <li> SHD$_{\mathcal{L}_1}$ > SHD$_{M_1}$ <br> $\implies M_1$ better </li>
                  </ul>
                </div>
              </div>
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ## Agent $\mathcal{A}_2$
              ----

              <div class="r-stack">
                <img data-src="res/fig62_net_v2_shaded_1.png" height="75%">
                <img class="fragment" data-src="res/fig63bis_net_v2_shaded_1.png" height="75%">
              </div>
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ## Agent $\mathcal{A}_2$
              ----

              <style>
                .container{
                  display: flex;
                }
                .col{
                  flex: 1;
                }
              </style>
              <div class="container">
                <div class="col">
                  <img data-src="res/fig62_net_v2_shaded_1.png">
                </div>
                <div class="col">
                  <img data-src="res/fig63bis_net_v2_shaded_1.png">
                </div>
              </div>
              <div class="container">
                <div class="col">
                  <ul>
                    <li> FP$_{\mathcal{L}_2}$ = FP$_{M_2}$ </li>
                    <li> FN$_{\mathcal{L}_2}$ > FN$_{M_2}$ </li>
                  </ul>
                </div>
                <div class="col">
                  <ul>
                    <li> SHD$_{\mathcal{L}_2}$ >> SHD$_{M_2}$ <br> $\implies M_2$ better </li>
                  </ul>
                </div>
              </div>
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ## FP across GT complexity
              ----

              <img data-src="res/performance-false-positives-2.jpg">
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ## FP across GT complexity
              ----

              <style>
                .container{
                  display: flex;
                }
                .col{
                  flex: 1;
                }
              </style>
              <div class="container">
                <div class="col">
                  <img data-src="res/performance-false-positives-2.jpg">
                </div>
                <div class="col">
                  Reasons?
                  <ul>
                    <li class="fragment" data-fragment-index="1"> no heuristic $\implies$ combinatorial explosion </li>
                    <li class="fragment" data-fragment-index="2"> local algorithm (e.g. starts fully connected) </li>
                  </ul>
                </div>
              </div>
              <p class="fragment" data-fragment-index="2" style="color: darkgrey"> <em>(future work: compare different algorithms, scale up)</em> </p>
            </script>
          </section>
          <section data-markdown data-auto-animate>
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ## Time across GT complexity
              ----

              <img data-src="res/performance-time-crop-2.jpg">
            </script>
          </section>
          <section data-markdown data-auto-animate="">
            <script type="text/template">
              <!-- .slide: data-transition="slide" -->
              ## Time across GT complexity
              ----

              <style>
                .container{
                  display: flex;
                }
                .col{
                  flex: 1;
                }
              </style>
              <div class="container">
                <div class="col">
                  <img data-src="res/performance-time-crop-2.jpg">
                </div>
                <div class="col">
                  Reasons?
                  <ul>
                    <li class="fragment" data-fragment-index="1"> complexity of (conditional) independence tests </li>
                    <li class="fragment" data-fragment-index="2"> interventions are fast <strong>in simulated env</strong> </li>
                  </ul>
                </div>
              </div>
              <p class="fragment" data-fragment-index="2" style="color: darkgrey"> <em>(future work: add delays to simulation, test in vitro)</em> </p>
            </script>
          </section>
        </section>

        <section data-markdown data-transition="convex" data-background-image="res/conclusion.jpg" data-background-opacity=0.25 data-background-size="cover">
          <script type="text/template">
            ## Conclusion
            ----

            1. first-step towards **multi-agent causal discovery**
            2. <!-- .element: class="fragment" -->general collaboration protocol with pluggable local algorithm
            3. <!-- .element: class="fragment" -->promising accuracy and performance results
            4. <!-- .element: class="fragment" -->enabler for provably-correct decision-making beyond ML statistical models
            5. &shy;<!-- .element: class="fragment" -->enabler for agents' learning-driven **adaptation**
          </script>
        </section>

        <section data-transition="convex" data-background-image="res/confused-meme.png" data-background-opacity=0.25 data-background-size="cover">
          <h3> Thanks </h3>
          <h3> for your attention </h3>
          <hr>
          <p><a href="mailto:stefano.mariani@unimore.it"> Stefano Mariani </a></p>
          <hr>
          <style>
            .container{
              display: flex;
            }
            .col{
              flex: 1;
            }
          </style>
          <div class="container">
            <div class="col">
              <br>
              <p><strong>Questions welcome :)</strong></p>
            </div>
            <div class="col">
              <img width="65%" data-src="res/these-slides.png">
            </div>
            <div class="col">
              <br>
              <p>$\Leftarrow$ get these slides :)</p>
            </div>
          </div>
          <p>(also: <em>we are having fun, join us!</em>)</p>
        </section>

      </div>
    </div>

    <script src="reveal.js/dist/reveal.js"></script>
    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script src="reveal.js/plugin/zoom/zoom.js"></script>
    <script src="reveal.js/plugin/math/math.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,
        progress: true,
        slideNumber: true,
        //autoSlide: 3000,
        transition: "convex",
        backgroundTransition: "fade",
        pdfSeparateFragments: false,
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom, RevealMath],
      });
    </script>
  </body>
</html>
